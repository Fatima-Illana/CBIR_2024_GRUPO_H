{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:36:51.777 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import faiss\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from skimage import io, color\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_cropper import st_cropper    \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "FILES_PATH = str(pathlib.Path().resolve())\n",
    "\n",
    "# Path in which the images should be located\n",
    "IMAGES_PATH = os.path.join(FILES_PATH, 'DatasetArteTrainTest/Train')\n",
    "# Path in which the database should be located\n",
    "DB_PATH = os.path.join(FILES_PATH, 'database')\n",
    "DB_FILE = 'db.csv' # name of the database\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Cargar la imagen\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    # Redimensionar la imagen al tamaño objetivo\n",
    "    img = img.resize(target_size)\n",
    "    # Convertir la imagen en un array de numpy y normalizar (escalar píxeles a 0-1)\n",
    "    img_array = np.array(img)\n",
    "    return img_array\n",
    "\n",
    "def get_image_list():\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DB_PATH, DB_FILE))\n",
    "    image_list = list(df.image.values)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def calculate_histograms(image, bins=32):\n",
    "    red = cv2.calcHist([image], [2], None, [bins], [0, 256])\n",
    "    green = cv2.calcHist([image], [1], None, [bins], [0, 256])\n",
    "    blue = cv2.calcHist([image], [0], None, [bins], [0, 256])\n",
    "    vector = np.concatenate([red, green, blue], axis=0)\n",
    "    vector = vector.reshape(-1)\n",
    "    vector = np.array(vector)\n",
    "    vector = vector.reshape(vector.shape[0], -1)\n",
    "    vector = vector.reshape(1, -1)\n",
    "    return vector\n",
    "\n",
    "def calcular_histograma_textura(imagen, distancias=[5], angulos=[45]):\n",
    "    \"\"\"\n",
    "    Calcula un histograma basado en propiedades de textura (GLCM).\n",
    "    \"\"\"\n",
    "    imagen_gris = rgb2gray(imagen)\n",
    "    imagen_gris = (imagen_gris * 255).astype(np.uint8)\n",
    "\n",
    "    # Calcular GLCM\n",
    "    glcm = graycomatrix(imagen_gris, distances=distancias, angles=angulos, symmetric=True, normed=True)\n",
    "    \n",
    "    # Propiedades de textura\n",
    "    propiedades = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    valores_textura = {prop: graycoprops(glcm, prop).flatten() for prop in propiedades}\n",
    "    \n",
    "    # Crear un histograma concatenando los valores de textura\n",
    "    histograma = np.concatenate([valores_textura[prop] for prop in propiedades])\n",
    "    histograma = histograma.reshape(histograma.shape[0], -1)\n",
    "    histograma = histograma.reshape(1, -1)\n",
    "    return histograma\n",
    "\n",
    "def extract_image_patches(image, random_state, patch_size=(30, 30), n_patches=250):\n",
    "    patches = extract_patches_2d(\n",
    "        image, \n",
    "        patch_size=patch_size, \n",
    "        max_patches=n_patches, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    return patches.reshape((n_patches, -1))\n",
    "\n",
    "def bag_of_words_extractor(img_query):\n",
    "    codebook = np.load('Bag_Of_Words.npy')\n",
    "    orb = cv2.ORB_create()\n",
    "    image = np.asarray(img_query)\n",
    "    patch_size=(30, 30)\n",
    "    n_patches=250\n",
    "    random_seed=0\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "    patches = []\n",
    "    patches.append(extract_image_patches(image, random_state, patch_size, n_patches))\n",
    "\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    for patch in patches:\n",
    "        patch_keypoints, patch_descriptors = orb.detectAndCompute(patch, None)\n",
    "        keypoints.append(patch_keypoints)\n",
    "        descriptors.append(patch_descriptors)\n",
    "\n",
    "    visual_words = [vq(desc, codebook)[0] for desc in descriptors]\n",
    "    frequency_values = [np.bincount(word, minlength=250) for word in visual_words]\n",
    "    frequency_values = np.float32(frequency_values)\n",
    "    faiss.normalize_L2(frequency_values)\n",
    "\n",
    "    return frequency_values\n",
    "\n",
    "def compute_deep_features(image):\n",
    "    # Carga el modelo preentrenado VGG19\n",
    "    base_model = VGG19(weights='imagenet', include_top=False)\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
    "    # Ajusta la imagen al tamaño esperado por el modelo\n",
    "    image_resized = cv2.resize(image, (224, 224))\n",
    "    image_array = np.expand_dims(image_resized, axis=0)\n",
    "    image_preprocessed = preprocess_input(image_array)\n",
    "    # Extrae características\n",
    "    features = model.predict(image_preprocessed)\n",
    "    features = features.flatten()\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "def autoencoder_extractor(image: np.array, encoder):\n",
    "    # batch dimension\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    feature_vector = encoder.predict(image)\n",
    "    feature_vector = feature_vector.reshape(1, -1)\n",
    "    return feature_vector\n",
    "\n",
    "def retrieve_image(img_query, feature_extractor, n_imgs=11):\n",
    "\n",
    "    if (feature_extractor == 'Extractor 1: Histograma Color'):\n",
    "        model_feature_extractor = calculate_histograms(img_query)\n",
    "        indexer = faiss.read_index(os.path.join(DB_PATH,  'feat_extract_1.index'))\n",
    "        if model_feature_extractor is None:\n",
    "            return None\n",
    "\n",
    "    elif (feature_extractor == 'Extractor 2: Texturas'):\n",
    "        model_feature_extractor = calcular_histograma_textura(img_query)\n",
    "        indexer = faiss.read_index(os.path.join(DB_PATH,  'feat_extract_2.index'))\n",
    "        if model_feature_extractor is None:\n",
    "            return None\n",
    "\n",
    "    elif (feature_extractor == 'Extractor 3: Bag Of Words'):\n",
    "        model_feature_extractor = bag_of_words_extractor(img_query)\n",
    "        indexer = faiss.read_index(os.path.join(DB_PATH,  'feat_extract_3.index'))\n",
    "        if model_feature_extractor is None:\n",
    "            return None\n",
    "\n",
    "    elif (feature_extractor == 'Extractor 4: CNN-VGG19'):\n",
    "        img_query = np.array(img_query) / 255.0\n",
    "        model_feature_extractor = compute_deep_features(img_query)\n",
    "        indexer = faiss.read_index(os.path.join(DB_PATH,  'feat_extract_4.index'))\n",
    "        if model_feature_extractor is None:\n",
    "            return None\n",
    "        \n",
    "    elif (feature_extractor == 'Extractor 5: Autoencoder'):\n",
    "        img_query = np.array(img_query) / 255.0\n",
    "        filename = 'autoencoder.keras'\n",
    "        autoencoder = keras.models.load_model(filename)\n",
    "        encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('dec_conv0').output)\n",
    "        model_feature_extractor = autoencoder_extractor(img_query, encoder)\n",
    "        indexer = faiss.read_index(os.path.join(DB_PATH,  'feat_extract_5.index'))\n",
    "        if model_feature_extractor is None:\n",
    "            return None\n",
    "    \n",
    "    else:\n",
    "        model_feature_extractor = calculate_histograms(img_query)\n",
    "        indexer = faiss.read_index(os.path.join(DB_PATH,  'feat_extract_1.index'))\n",
    "        if model_feature_extractor is None:\n",
    "            return None\n",
    "\n",
    "    # TODO: Modify accordingly\n",
    "\n",
    "    _, indices = indexer.search(model_feature_extractor, k=n_imgs)\n",
    "\n",
    "    return indices[0]\n",
    "\n",
    "def metric_precision(img_query, retriev, k_values=[1, 3, 5, 7, 11]):\n",
    "    img_query_name = img_query.split('-')[1].split('.')[0]   \n",
    "    image_list = get_image_list()\n",
    "    precision_values = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        if k > len(retriev):\n",
    "            continue  # Skip if k is not possible\n",
    "\n",
    "        retrieved_image_names = [image_list[retriev[i]].split('-')[1].split('.')[0] for i in range(k)]\n",
    "        # Count number of images with same label. \n",
    "        relevant_count = sum(1 for img in retrieved_image_names if img == img_query_name)\n",
    "        precision = relevant_count / k\n",
    "        precision_values[k] = round(precision, 2)\n",
    "        \n",
    "    return precision_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(): \n",
    "    extractores = ['Extractor 1: Histograma Color', 'Extractor 2: Texturas', 'Extractor 3: Bag Of Words', 'Extractor 4: CNN-VGG19', 'Extractor 5: Autoencoder']\n",
    "    df_columns = ['1_K1', '1_K3', '1_K5', '1_K7', '1_K11', '2_K1', '2_K3', '2_K5', '2_K7', '2_K11', '3_K1', '3_K3', '3_K5', '3_K7', '3_K11', '4_K1', '4_K3', '4_K5', \n",
    "                '4_K7', '4_K11', '5_K1', '5_K3', '5_K5', '5_K7', '5_K11', 'Movement']\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "    test_dir = \"./DatasetArteTrainTest/Test/\"\n",
    "    n_test = len(os.listdir(test_dir))\n",
    "\n",
    "    for i in range(n_test):\n",
    "        query_index = i\n",
    "        query_image_dir = Path(os.path.join(test_dir, os.listdir(test_dir)[query_index]))\n",
    "        query_image = preprocess_image(query_image_dir)\n",
    "        label = query_image_dir.name.split('-')[1].split('.')[0]\n",
    "        df.loc[i, 'Movement'] = label\n",
    "        for j in range(len(extractores)):\n",
    "            extractor = extractores[j]\n",
    "            similar_images = retrieve_image(query_image, extractor)\n",
    "            precision_results = metric_precision(query_image_dir.name, similar_images)\n",
    "            for k, precision in precision_results.items():\n",
    "                column_name = str(j+1)+'_K'+str(k)\n",
    "                df.loc[i, column_name] = precision\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n"
     ]
    }
   ],
   "source": [
    "archivo_excel = 'ResultadosCBIR.xlsx'\n",
    "\n",
    "if os.path.exists(archivo_excel):\n",
    "    df = pd.read_excel(archivo_excel)\n",
    "else:\n",
    "    df = calculate_results()\n",
    "    df.to_excel('ResultadosCBIR.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_K1</th>\n",
       "      <th>1_K3</th>\n",
       "      <th>1_K5</th>\n",
       "      <th>1_K7</th>\n",
       "      <th>1_K11</th>\n",
       "      <th>2_K1</th>\n",
       "      <th>2_K3</th>\n",
       "      <th>2_K5</th>\n",
       "      <th>2_K7</th>\n",
       "      <th>2_K11</th>\n",
       "      <th>...</th>\n",
       "      <th>4_K3</th>\n",
       "      <th>4_K5</th>\n",
       "      <th>4_K7</th>\n",
       "      <th>4_K11</th>\n",
       "      <th>5_K1</th>\n",
       "      <th>5_K3</th>\n",
       "      <th>5_K5</th>\n",
       "      <th>5_K7</th>\n",
       "      <th>5_K11</th>\n",
       "      <th>Movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Rococo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Rococo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Rococo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Rococo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>Baroque</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  1_K1 1_K3 1_K5 1_K7 1_K11 2_K1  2_K3 2_K5  2_K7 2_K11  ... 4_K3 4_K5  4_K7  \\\n",
       "0  1.0  1.0  1.0  1.0   1.0  0.0  0.33  0.6  0.43  0.45  ...  1.0  1.0   1.0   \n",
       "1  1.0  1.0  1.0  1.0   1.0  0.0  0.33  0.2  0.43  0.27  ...  1.0  0.8  0.71   \n",
       "2  1.0  1.0  1.0  1.0   1.0  1.0  0.67  0.4  0.43  0.27  ...  1.0  1.0   1.0   \n",
       "3  1.0  1.0  1.0  1.0   1.0  1.0  0.33  0.4  0.57  0.64  ...  1.0  1.0   1.0   \n",
       "4  1.0  1.0  1.0  1.0  0.91  0.0   0.0  0.0   0.0   0.0  ...  0.0  0.0  0.14   \n",
       "\n",
       "  4_K11 5_K1  5_K3 5_K5  5_K7 5_K11 Movement  \n",
       "0   1.0  1.0  0.67  0.6  0.71  0.55   Rococo  \n",
       "1  0.55  0.0  0.33  0.6  0.71  0.73   Rococo  \n",
       "2   1.0  1.0  0.67  0.8  0.86  0.73   Rococo  \n",
       "3   1.0  1.0   1.0  0.8  0.86  0.64   Rococo  \n",
       "4  0.18  1.0   1.0  0.8  0.86  0.91  Baroque  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histograma de Color para k =  1 :  0.69\n",
      "Texturas para k =  1 :  0.25\n",
      "Bag Of Words para k =  1 :  0.44\n",
      "VGG19 para k =  1 :  0.56\n",
      "Autoencoder para k =  1 :  0.86\n",
      "Histograma de Color para k =  3 :  0.69\n",
      "Texturas para k =  3 :  0.28\n",
      "Bag Of Words para k =  3 :  0.47\n",
      "VGG19 para k =  3 :  0.57\n",
      "Autoencoder para k =  3 :  0.84\n",
      "Histograma de Color para k =  5 :  0.64\n",
      "Texturas para k =  5 :  0.28\n",
      "Bag Of Words para k =  5 :  0.45\n",
      "VGG19 para k =  5 :  0.54\n",
      "Autoencoder para k =  5 :  0.84\n",
      "Histograma de Color para k =  7 :  0.62\n",
      "Texturas para k =  7 :  0.27\n",
      "Bag Of Words para k =  7 :  0.43\n",
      "VGG19 para k =  7 :  0.5\n",
      "Autoencoder para k =  7 :  0.83\n",
      "Histograma de Color para k =  11 :  0.61\n",
      "Texturas para k =  11 :  0.25\n",
      "Bag Of Words para k =  11 :  0.39\n",
      "VGG19 para k =  11 :  0.47\n",
      "Autoencoder para k =  11 :  0.78\n"
     ]
    }
   ],
   "source": [
    "columns_1 = [col for col in df.columns if '1_' in col]\n",
    "means_1 = df[columns_1].mean()\n",
    "\n",
    "columns_2 = [col for col in df.columns if '2_' in col]\n",
    "means_2 = df[columns_2].mean()\n",
    "\n",
    "columns_3 = [col for col in df.columns if '3_' in col]\n",
    "means_3 = df[columns_3].mean()\n",
    "\n",
    "columns_4 = [col for col in df.columns if '4_' in col]\n",
    "means_4 = df[columns_4].mean()\n",
    "\n",
    "columns_5 = [col for col in df.columns if '5_' in col]\n",
    "means_5 = df[columns_5].mean()\n",
    "\n",
    "k =[1, 3, 5, 7, 11]\n",
    "for i in range(5):\n",
    "    print('Histograma de Color para k = ', k[i], ': ', round(means_1.iloc[i], 2))\n",
    "    print('Texturas para k = ', k[i], ': ', round(means_2.iloc[i], 2))\n",
    "    print('Bag Of Words para k = ', k[i], ': ', round(means_3.iloc[i], 2))\n",
    "    print('VGG19 para k = ', k[i], ': ', round(means_4.iloc[i], 2))\n",
    "    print('Autoencoder para k = ', k[i], ': ', round(means_5.iloc[i], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Histograma de Color:  0.65\n",
      "Media Texturas:  0.27\n",
      "Media Bag Of Words:  0.44\n",
      "Media VGG19:  0.53\n",
      "Media Autoencoder:  0.83\n"
     ]
    }
   ],
   "source": [
    "print('Media Histograma de Color: ', round(means_1.mean(), 2))\n",
    "print('Media Texturas: ', round(means_2.mean(), 2))\n",
    "print('Media Bag Of Words: ', round(means_3.mean(), 2))\n",
    "print('Media VGG19: ', round(means_4.mean(), 2))\n",
    "print('Media Autoencoder: ', round(means_5.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_rococo = list(df.loc[df['Movement'] == 'Rococo'].index)\n",
    "indices_baroque = df.loc[df['Movement'] == 'Baroque'].index\n",
    "indices_realism = df.loc[df['Movement'] == 'Realism'].index\n",
    "indices_japanese = df.loc[df['Movement'] == 'Japanese_Art'].index\n",
    "indices_art_nouveau = df.loc[df['Movement'] == 'Art_Nouveau'].index\n",
    "indices_medieval = df.loc[df['Movement'] == 'Western_Medieval'].index\n",
    "titulos_indices = ['Rococo', 'Baroque', 'Realism', 'Japanese_Art', 'Art_Nouveau', 'Western_Medieval']\n",
    "\n",
    "extractor_1 = df[columns_1]\n",
    "extractor_2 = df[columns_2]\n",
    "extractor_3 = df[columns_3]\n",
    "extractor_4 = df[columns_4]\n",
    "extractor_5 = df[columns_5]\n",
    "\n",
    "indices_movimientos = [indices_rococo, indices_baroque, indices_realism, indices_japanese, indices_art_nouveau, indices_medieval]\n",
    "df_extractores = [extractor_1, extractor_2, extractor_3, extractor_4, extractor_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media extractor  0  en  Rococo :  0.78\n",
      "Media extractor  0  en  Baroque :  0.91\n",
      "Media extractor  0  en  Realism :  0.64\n",
      "Media extractor  0  en  Japanese_Art :  0.46\n",
      "Media extractor  0  en  Art_Nouveau :  0.75\n",
      "Media extractor  0  en  Western_Medieval :  0.35\n",
      "Media extractor  1  en  Rococo :  0.29\n",
      "Media extractor  1  en  Baroque :  0.15\n",
      "Media extractor  1  en  Realism :  0.29\n",
      "Media extractor  1  en  Japanese_Art :  0.3\n",
      "Media extractor  1  en  Art_Nouveau :  0.27\n",
      "Media extractor  1  en  Western_Medieval :  0.3\n",
      "Media extractor  2  en  Rococo :  0.47\n",
      "Media extractor  2  en  Baroque :  0.59\n",
      "Media extractor  2  en  Realism :  0.33\n",
      "Media extractor  2  en  Japanese_Art :  0.25\n",
      "Media extractor  2  en  Art_Nouveau :  0.48\n",
      "Media extractor  2  en  Western_Medieval :  0.5\n",
      "Media extractor  3  en  Rococo :  0.67\n",
      "Media extractor  3  en  Baroque :  0.16\n",
      "Media extractor  3  en  Realism :  0.69\n",
      "Media extractor  3  en  Japanese_Art :  0.4\n",
      "Media extractor  3  en  Art_Nouveau :  0.64\n",
      "Media extractor  3  en  Western_Medieval :  0.62\n",
      "Media extractor  4  en  Rococo :  0.7\n",
      "Media extractor  4  en  Baroque :  0.91\n",
      "Media extractor  4  en  Realism :  0.99\n",
      "Media extractor  4  en  Japanese_Art :  0.72\n",
      "Media extractor  4  en  Art_Nouveau :  0.82\n",
      "Media extractor  4  en  Western_Medieval :  0.85\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for extractor in df_extractores:\n",
    "    j = 0\n",
    "    for movimiento in indices_movimientos:\n",
    "        print('Media extractor ', i, ' en ', titulos_indices[j], ': ', round(extractor.loc[movimiento, :].mean().mean(), 2))\n",
    "        j += 1\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
